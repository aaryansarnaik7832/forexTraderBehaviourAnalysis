{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-28T22:10:23.655284Z",
     "start_time": "2024-12-28T22:10:23.389743Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T22:10:31.612906Z",
     "start_time": "2024-12-28T22:10:24.226315Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trading_history = pd.read_csv('dropped_files/trading_history_data.csv')\n",
    "overview = pd.read_csv('dropped_files/overview_page_data.csv')\n",
    "er = pd.read_csv('dropped_files/exchangerate.csv')\n",
    "compute = pd.read_csv('dropped_files/compute1.csv')\n",
    "\n",
    "trading_history.loc[:, 'date_open'] = pd.to_datetime(trading_history['date_open'])\n",
    "trading_history.loc[:, 'date_closed'] = pd.to_datetime(trading_history['date_closed'])\n",
    "\n",
    "overview.loc[:, 'scraped_on'] = pd.to_datetime(overview['scraped_on'])\n",
    "\n",
    "er.loc[:, 'time'] = pd.to_datetime(er['time'])\n",
    "\n",
    "compute.loc[:, 'open_date'] = pd.to_datetime(compute['open_date'])\n",
    "compute.loc[:, 'close_date'] = pd.to_datetime(compute['close_date'])\n",
    "compute.loc[:, 'open_date2'] = pd.to_datetime(compute['open_date2'])"
   ],
   "id": "190f963c7a0c5c5b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T22:10:34.051719Z",
     "start_time": "2024-12-28T22:10:33.141997Z"
    }
   },
   "cell_type": "code",
   "source": "trading_history = trading_history.drop_duplicates()",
   "id": "f4960b64a4c8a838",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T22:10:39.717217Z",
     "start_time": "2024-12-28T22:10:39.705863Z"
    }
   },
   "cell_type": "code",
   "source": "trading_history.head()",
   "id": "58c4292c33ac186a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user_id   trade_id  lots trade_type            date_open  \\\n",
       "0    24632  514812394  1.00        BUY  2019-10-14 20:11:11   \n",
       "1   388129  517500344  0.01        BUY  2019-11-15 16:00:00   \n",
       "2   373754  517456832  0.20       SELL  2019-11-15 06:36:31   \n",
       "3   300553  517256771  1.00        BUY  2019-11-13 12:35:06   \n",
       "4   300553  517365782  1.00        BUY  2019-11-14 09:16:01   \n",
       "\n",
       "           date_closed  price_open  price_closed currency  \n",
       "0  2019-11-17 17:23:15   108.67300     109.78000  CHF/JPY  \n",
       "1  2019-11-17 17:01:01     1.89337       1.89552  GBP/AUD  \n",
       "2  2019-11-15 16:57:49     1.89611       1.89197  GBP/AUD  \n",
       "3  2019-11-15 16:02:09     0.67633       0.67429  AUD/CHF  \n",
       "4  2019-11-15 16:02:05     0.67028       0.67431  AUD/CHF  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>trade_id</th>\n",
       "      <th>lots</th>\n",
       "      <th>trade_type</th>\n",
       "      <th>date_open</th>\n",
       "      <th>date_closed</th>\n",
       "      <th>price_open</th>\n",
       "      <th>price_closed</th>\n",
       "      <th>currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24632</td>\n",
       "      <td>514812394</td>\n",
       "      <td>1.00</td>\n",
       "      <td>BUY</td>\n",
       "      <td>2019-10-14 20:11:11</td>\n",
       "      <td>2019-11-17 17:23:15</td>\n",
       "      <td>108.67300</td>\n",
       "      <td>109.78000</td>\n",
       "      <td>CHF/JPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>388129</td>\n",
       "      <td>517500344</td>\n",
       "      <td>0.01</td>\n",
       "      <td>BUY</td>\n",
       "      <td>2019-11-15 16:00:00</td>\n",
       "      <td>2019-11-17 17:01:01</td>\n",
       "      <td>1.89337</td>\n",
       "      <td>1.89552</td>\n",
       "      <td>GBP/AUD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>373754</td>\n",
       "      <td>517456832</td>\n",
       "      <td>0.20</td>\n",
       "      <td>SELL</td>\n",
       "      <td>2019-11-15 06:36:31</td>\n",
       "      <td>2019-11-15 16:57:49</td>\n",
       "      <td>1.89611</td>\n",
       "      <td>1.89197</td>\n",
       "      <td>GBP/AUD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300553</td>\n",
       "      <td>517256771</td>\n",
       "      <td>1.00</td>\n",
       "      <td>BUY</td>\n",
       "      <td>2019-11-13 12:35:06</td>\n",
       "      <td>2019-11-15 16:02:09</td>\n",
       "      <td>0.67633</td>\n",
       "      <td>0.67429</td>\n",
       "      <td>AUD/CHF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300553</td>\n",
       "      <td>517365782</td>\n",
       "      <td>1.00</td>\n",
       "      <td>BUY</td>\n",
       "      <td>2019-11-14 09:16:01</td>\n",
       "      <td>2019-11-15 16:02:05</td>\n",
       "      <td>0.67028</td>\n",
       "      <td>0.67431</td>\n",
       "      <td>AUD/CHF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T22:16:24.154159Z",
     "start_time": "2024-12-28T22:16:24.149256Z"
    }
   },
   "cell_type": "code",
   "source": "er",
   "id": "1f8e78db282ab582",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                        time     high      low    close    unit\n",
       "0        2013-05-16 00:00:00  0.95671  0.95534  0.95647  AUDCHF\n",
       "1        2013-05-16 01:00:00  0.95663  0.95537  0.95576  AUDCHF\n",
       "2        2013-05-16 02:00:00  0.95645  0.95538  0.95550  AUDCHF\n",
       "3        2013-05-16 03:00:00  0.95577  0.95392  0.95398  AUDCHF\n",
       "4        2013-05-16 04:00:00  0.95410  0.95331  0.95404  AUDCHF\n",
       "...                      ...      ...      ...      ...     ...\n",
       "1114662  2021-05-26 10:00:00  0.93969  0.93888  0.93933  AUDCAD\n",
       "1114663  2021-05-26 11:00:00  0.93978  0.93918  0.93935  AUDCAD\n",
       "1114664  2021-05-26 12:00:00  0.94087  0.93911  0.94001  AUDCAD\n",
       "1114665  2021-05-26 13:00:00  0.94001  0.93816  0.93823  AUDCAD\n",
       "1114666  2021-05-26 14:00:00  0.93852  0.93695  0.93747  AUDCAD\n",
       "\n",
       "[1114667 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-05-16 00:00:00</td>\n",
       "      <td>0.95671</td>\n",
       "      <td>0.95534</td>\n",
       "      <td>0.95647</td>\n",
       "      <td>AUDCHF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-05-16 01:00:00</td>\n",
       "      <td>0.95663</td>\n",
       "      <td>0.95537</td>\n",
       "      <td>0.95576</td>\n",
       "      <td>AUDCHF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-05-16 02:00:00</td>\n",
       "      <td>0.95645</td>\n",
       "      <td>0.95538</td>\n",
       "      <td>0.95550</td>\n",
       "      <td>AUDCHF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-05-16 03:00:00</td>\n",
       "      <td>0.95577</td>\n",
       "      <td>0.95392</td>\n",
       "      <td>0.95398</td>\n",
       "      <td>AUDCHF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-05-16 04:00:00</td>\n",
       "      <td>0.95410</td>\n",
       "      <td>0.95331</td>\n",
       "      <td>0.95404</td>\n",
       "      <td>AUDCHF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114662</th>\n",
       "      <td>2021-05-26 10:00:00</td>\n",
       "      <td>0.93969</td>\n",
       "      <td>0.93888</td>\n",
       "      <td>0.93933</td>\n",
       "      <td>AUDCAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114663</th>\n",
       "      <td>2021-05-26 11:00:00</td>\n",
       "      <td>0.93978</td>\n",
       "      <td>0.93918</td>\n",
       "      <td>0.93935</td>\n",
       "      <td>AUDCAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114664</th>\n",
       "      <td>2021-05-26 12:00:00</td>\n",
       "      <td>0.94087</td>\n",
       "      <td>0.93911</td>\n",
       "      <td>0.94001</td>\n",
       "      <td>AUDCAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114665</th>\n",
       "      <td>2021-05-26 13:00:00</td>\n",
       "      <td>0.94001</td>\n",
       "      <td>0.93816</td>\n",
       "      <td>0.93823</td>\n",
       "      <td>AUDCAD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114666</th>\n",
       "      <td>2021-05-26 14:00:00</td>\n",
       "      <td>0.93852</td>\n",
       "      <td>0.93695</td>\n",
       "      <td>0.93747</td>\n",
       "      <td>AUDCAD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1114667 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T15:16:22.497613Z",
     "start_time": "2024-12-27T15:16:22.477265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Functions\n",
    "\n",
    "def create_user_scrapes_dict(overview_df):\n",
    "    user_scrapes = {}\n",
    "    for _, row in overview_df.iterrows():\n",
    "        user_id = row['userid']\n",
    "        scrape_date = row['scraped_on']\n",
    "        views = row['viewed_no_of_times']\n",
    "        weeks = row['weeks']\n",
    "        profit_in_pips = row['profit_in_pips']\n",
    "        trades = row['trades']\n",
    "        if user_id not in user_scrapes:\n",
    "            user_scrapes[user_id] = []\n",
    "        user_scrapes[user_id].append((scrape_date, views, weeks, profit_in_pips, trades))\n",
    "    \n",
    "    # Sort scrape dates for each user\n",
    "    for user_id in user_scrapes:\n",
    "        user_scrapes[user_id].sort(key=lambda x: x[0])\n",
    "    \n",
    "    return user_scrapes\n",
    "\n",
    "\n",
    "def create_derived_variables(trading_history_df, user_scrapes):\n",
    "    derived_variables = []\n",
    "    trade_counter = {}\n",
    "    \n",
    "    for _, trade in trading_history_df.iterrows():\n",
    "        user_id = trade['user_id']\n",
    "        trade_id = trade['trade_id']\n",
    "        date_open = trade['date_open']\n",
    "        date_closed = trade['date_closed']\n",
    "        currency = trade['currency']\n",
    "        lots = trade['lots']\n",
    "        \n",
    "        # Assign trade_no\n",
    "        if user_id not in trade_counter:\n",
    "            trade_counter[user_id] = 1\n",
    "        else:\n",
    "            trade_counter[user_id] += 1\n",
    "        trade_no = trade_counter[user_id]\n",
    "        \n",
    "        if user_id in user_scrapes:\n",
    "            relevant_scrapes = [\n",
    "                (scrape_date, views, weeks, profit_in_pips, trades) \n",
    "                for scrape_date, views, weeks, profit_in_pips, trades in user_scrapes[user_id]\n",
    "                if date_open <= scrape_date <= date_closed\n",
    "            ]\n",
    "            \n",
    "            prev_views = None\n",
    "            for obs_num, (scrape_date, views, weeks, profit_in_pips, trades) in enumerate(relevant_scrapes, start=1):\n",
    "                new_row = {\n",
    "                    'user_id': user_id,\n",
    "                    'trade_id': trade_id,\n",
    "                    'trade_no': trade_no,\n",
    "                    'observation_number': obs_num,\n",
    "                    'date_open': date_open,\n",
    "                    'date_closed': date_closed,\n",
    "                    'date_observed': scrape_date,\n",
    "                    'views': views,\n",
    "                    'views_previous': prev_views,\n",
    "                    'currency': currency,\n",
    "                    'lots': lots,\n",
    "                    'cum_day': weeks * 7,  # Converting weeks to days\n",
    "                    'cum_profit_in_pips': profit_in_pips,\n",
    "                    'cum_trades': trades\n",
    "                }\n",
    "                derived_variables.append(new_row)\n",
    "                prev_views = views\n",
    "            \n",
    "            # Check if last observed date is less than date_closed\n",
    "            if relevant_scrapes and relevant_scrapes[-1][0] < date_closed:\n",
    "                last_scrape = relevant_scrapes[-1]\n",
    "                derived_variables.append({\n",
    "                    'user_id': user_id,\n",
    "                    'trade_id': trade_id,\n",
    "                    'trade_no': trade_no,\n",
    "                    'observation_number': len(relevant_scrapes) + 1,\n",
    "                    'date_open': date_open,\n",
    "                    'date_closed': date_closed,\n",
    "                    'date_observed': date_closed,\n",
    "                    'views': last_scrape[1], # Using the last known value\n",
    "                    'views_previous': last_scrape[1],\n",
    "                    'currency': currency,\n",
    "                    'lots': lots,\n",
    "                    'cum_day': last_scrape[2] * 7,  # Using the last known value\n",
    "                    'cum_profit_in_pips': last_scrape[3],  # Using the last known value\n",
    "                    'cum_trades': last_scrape[4]  # Using the last known value\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(derived_variables)\n",
    "\n",
    "\n",
    "def get_lowest_rate(currency, start_date, end_date):\n",
    "    if currency in exchange_rates_dict:\n",
    "        rates = [rate for date, rate in exchange_rates_dict[currency].items() \n",
    "                 if start_date <= date <= end_date]\n",
    "        return min(rates) if rates else None\n",
    "    return None\n",
    "\n",
    "def get_24hr_avg_rate(currency, end_date):\n",
    "    if currency in exchange_rates_dict:\n",
    "        start_date = end_date - timedelta(hours=24)\n",
    "        rates = [rate for date, rate in exchange_rates_dict[currency].items() \n",
    "                 if start_date <= date < end_date]\n",
    "        return sum(rates) / len(rates) if rates else None\n",
    "    return None\n",
    "\n",
    "def get_avg_rate(currency, start_date, end_date):\n",
    "    if currency in exchange_rates_dict:\n",
    "        rates = [rate for date, rate in exchange_rates_dict[currency].items() \n",
    "                 if start_date <= date <= end_date]\n",
    "        return sum(rates) / len(rates) if rates else None\n",
    "    return None\n",
    "\n",
    "def calculate_rates(row):\n",
    "    currency = row['currency'].replace('/', '')\n",
    "    date_open = row['date_open'].floor('h')\n",
    "    date_observed = row['date_observed'].floor('h')\n",
    "    date_closed = row['date_closed'].floor('h')\n",
    "    \n",
    "    if currency in exchange_rates_dict:\n",
    "        lowest_rate = get_lowest_rate(currency, date_open, date_observed)\n",
    "        close_rate = exchange_rates_dict[currency].get(date_closed)\n",
    "        avg_24hr = get_24hr_avg_rate(currency, date_closed)\n",
    "        fx_rate_idx = get_avg_rate(currency, date_open, date_observed)\n",
    "        \n",
    "        neg_rate_diff = close_rate - lowest_rate if lowest_rate and close_rate else None\n",
    "        \n",
    "        return pd.Series({\n",
    "            'neg_rate_diff': neg_rate_diff,\n",
    "            '24hr_avg_rate': avg_24hr,\n",
    "            'fx_rate_idx': fx_rate_idx\n",
    "        })\n",
    "    \n",
    "    return pd.Series({'neg_rate_diff': None, '24hr_avg_rate': None, 'fx_rate_idx': None})\n",
    "\n",
    "# Keep the existing gain calculation\n",
    "def calculate_gain(row_curr):\n",
    "    currency_curr = row_curr['currency'].replace('/', '')\n",
    "    date_open_curr = row_curr['date_open'].floor('h')\n",
    "    date_observed_curr = row_curr['date_observed'].floor('h')\n",
    "    \n",
    "    if currency_curr in exchange_rates_dict:\n",
    "        currency_rates = exchange_rates_dict[currency_curr]\n",
    "        \n",
    "        if date_open_curr in currency_rates and date_observed_curr in currency_rates:\n",
    "            price_open_curr = currency_rates[date_open_curr]\n",
    "            price_observed = currency_rates[date_observed_curr]\n",
    "            \n",
    "            return 1 if price_observed > price_open_curr else 0\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_rank(user_id, date):\n",
    "    user_ranks = rank_dict.get(user_id, {})\n",
    "    return user_ranks.get(date, None)\n",
    "\n",
    "def get_average_rank(user_id, end_date):\n",
    "    start_date = end_date - timedelta(days=30)\n",
    "    user_ranks = rank_dict.get(user_id, {})\n",
    "    relevant_ranks = [rank for date, rank in user_ranks.items() if start_date <= date <= end_date]\n",
    "    return sum(relevant_ranks) / len(relevant_ranks) if relevant_ranks else None\n",
    "\n",
    "def calculate_rank_and_change(row):\n",
    "    user_id = row['user_id']\n",
    "    date_observed = row['date_observed'].floor('D')\n",
    "    date_open = row['date_open'].floor('D')\n",
    "    \n",
    "    observed_rank = get_rank(user_id, date_observed)\n",
    "    open_rank = get_rank(user_id, date_open)\n",
    "    avg_rank_1m = get_average_rank(user_id, date_observed)\n",
    "    \n",
    "    if observed_rank is None or open_rank is None:\n",
    "            return pd.Series({\n",
    "            'rank': None,\n",
    "            'rank_change': None,\n",
    "            'avg_rank_1m': None\n",
    "        }, index=['rank', 'rank_change', 'avg_rank_1m'])\n",
    "    \n",
    "    rank_change = open_rank - observed_rank\n",
    "    return pd.Series({\n",
    "        'rank': observed_rank,\n",
    "        'rank_change': rank_change,\n",
    "        'avg_rank_1m': avg_rank_1m\n",
    "    }, index=['rank', 'rank_change', 'avg_rank_1m'])\n",
    "\n",
    "\n",
    "def count_concurrent_trades_and_calculate_dispos_effect(row, trading_history_df, exchange_rates_dict):\n",
    "    user_id = row['user_id']\n",
    "    date_observed = pd.to_datetime(row['date_observed'])\n",
    "\n",
    "\n",
    "    trading_history_df['date_open'] = pd.to_datetime(trading_history_df['date_open'])\n",
    "    trading_history_df['date_closed'] = pd.to_datetime(trading_history_df['date_closed'])\n",
    "    \n",
    "    # Filter relevant trades\n",
    "    relevant_trades = trading_history_df[\n",
    "        (trading_history_df['user_id'] == user_id) &\n",
    "        (trading_history_df['date_open'] <= date_observed) &\n",
    "        (trading_history_df['date_closed'] >= date_observed)\n",
    "    ]\n",
    "    \n",
    "    # Count concurrent transactions and unique currencies\n",
    "    concurrent_count = len(relevant_trades)\n",
    "    unique_currencies = relevant_trades['currency'].nunique()\n",
    "    \n",
    "    # Divide into open and closed trades\n",
    "    open_trades = relevant_trades[relevant_trades['date_closed'].dt.date > date_observed.date()]\n",
    "    closed_trades = relevant_trades[relevant_trades['date_closed'].dt.date == date_observed.date()]\n",
    "    \n",
    "    def calculate_gain_loss(trades):\n",
    "        no_gain, no_loss = 0, 0\n",
    "        for _, trade in trades.iterrows():\n",
    "            currency = trade['currency'].replace('/', '')\n",
    "            date_open = trade['date_open'].floor('h')\n",
    "            date_observed_rounded = date_observed.floor('h')\n",
    "            \n",
    "            if currency in exchange_rates_dict:\n",
    "                open_rate = exchange_rates_dict[currency].get(date_open)\n",
    "                observed_rate = exchange_rates_dict[currency].get(date_observed_rounded)\n",
    "                \n",
    "                if open_rate is not None and observed_rate is not None:\n",
    "                    if observed_rate > open_rate:\n",
    "                        no_gain += 1\n",
    "                    elif observed_rate < open_rate:\n",
    "                        no_loss += 1\n",
    "        \n",
    "        return no_gain, no_loss\n",
    "    \n",
    "    no_open_gain, no_open_loss = calculate_gain_loss(open_trades)\n",
    "    no_closed_gain, no_closed_loss = calculate_gain_loss(closed_trades)\n",
    "    \n",
    "    # Calculate proportions\n",
    "    total_gains = no_closed_gain + no_open_gain\n",
    "    total_losses = no_closed_loss + no_open_loss\n",
    "    \n",
    "    prop_closed_gains = no_closed_gain / total_gains if total_gains > 0 else 0\n",
    "    prop_closed_loss = no_closed_loss / total_losses if total_losses > 0 else 0\n",
    "    \n",
    "    # Calculate disposition effect\n",
    "    dispos_effect = prop_closed_gains - prop_closed_loss\n",
    "    \n",
    "    return pd.Series({\n",
    "        'conc_transactions': concurrent_count,\n",
    "        'conc_currencies': unique_currencies,\n",
    "        'n_open_gain': no_open_gain,\n",
    "        'n_open_loss': no_open_loss,\n",
    "        'n_closed_gain': no_closed_gain,\n",
    "        'n_closed_loss': no_closed_loss,\n",
    "        'prop_closed_gains': prop_closed_gains,\n",
    "        'prop_closed_loss': prop_closed_loss,\n",
    "        'dispos_effect': dispos_effect\n",
    "    })\n",
    "\n",
    "\n",
    "def add_compute_columns(row, compute_df):\n",
    "    user_id = row['user_id']\n",
    "    trade_id = row['trade_id']\n",
    "    date_observed = row['date_observed'].floor('D')\n",
    "    \n",
    "    # Find the matching row in compute_df\n",
    "    matching_row = compute_df[\n",
    "        (compute_df['user_id'] == user_id) & \n",
    "        (compute_df['trade_id'] == trade_id) & \n",
    "        (compute_df['open_date2'] == date_observed)\n",
    "    ]\n",
    "    \n",
    "    if not matching_row.empty:\n",
    "        return pd.Series({\n",
    "            'followers': matching_row['followers'].values[0],\n",
    "            'amount_following': matching_row['amount_following'].values[0],\n",
    "            'total_follower_profit': matching_row['total_follower_profit'].values[0],\n",
    "            'gain_days': matching_row['cum_gain_days'].values[0],\n",
    "            'avg_slippage': matching_row['avg_slippage'].values[0]\n",
    "        })\n",
    "    else:\n",
    "        return pd.Series({\n",
    "            'followers': None,\n",
    "            'amount_following': None,\n",
    "            'total_follower_profit': None,\n",
    "            'gain_days': None,\n",
    "            'avg_slippage': None\n",
    "        })\n",
    "\n",
    "\n",
    "def find_cohort(user_id, trade_id, date_open, compute_df):\n",
    "    print(f\"Finding cohort for user_id: {user_id}, trade_id: {trade_id}, date_open: {date_open}\")\n",
    "    for i in range(4):  # Try original date and 3 more days\n",
    "        date_open = date_open.floor('D')\n",
    "        date = date_open + timedelta(days=i)\n",
    "        user_data = compute_df[(compute_df['user_id'] == user_id) & (compute_df['open_date2'] == date)]\n",
    "        \n",
    "        print(f\"  Checking date: {date}, user data found: {not user_data.empty}\")\n",
    "        \n",
    "        if not user_data.empty:\n",
    "            user_rank = user_data['zulu_rank'].values[0]\n",
    "            date_ranks = compute_df[compute_df['open_date2'] == date].sort_values('zulu_rank')\n",
    "            print(f\"  Min rank: {date_ranks['zulu_rank'].min()}, Max rank: {date_ranks['zulu_rank'].max()}\")\n",
    "            print(f\"  User rank: {user_rank}, Total ranks for this date: {len(date_ranks)}\")\n",
    "            \n",
    "            # Find users with ranks close to the user's rank\n",
    "            lower_ranks = date_ranks[date_ranks['zulu_rank'] <= user_rank].tail(6)  # Include the user\n",
    "            higher_ranks = date_ranks[date_ranks['zulu_rank'] > user_rank].head(5)\n",
    "            \n",
    "            cohort = pd.concat([lower_ranks, higher_ranks])['user_id'].tolist()\n",
    "            \n",
    "            print(f\"  Lower ranks: {lower_ranks['zulu_rank'].tolist()}\")\n",
    "            print(f\"  Higher ranks: {higher_ranks['zulu_rank'].tolist()}\")\n",
    "            print(f\"  Cohort found: {cohort}\")\n",
    "            print(f\"  Cohort size: {len(cohort)}\")\n",
    "            \n",
    "            return cohort\n",
    "    \n",
    "    print(\"  Cohort not found after checking 4 days\")\n",
    "    return None\n",
    "\n",
    "def calculate_cohort_min_rank(row, cohort_dict, compute_df):\n",
    "    user_id, trade_id = row['user_id'], row['trade_id']\n",
    "    date_open, date_observed = row['date_open'].floor('D'), row['date_observed'].floor('D')\n",
    "    \n",
    "    if (user_id, trade_id) not in cohort_dict:\n",
    "        cohort_dict[(user_id, trade_id)] = find_cohort(user_id, trade_id, date_open, compute_df)\n",
    "    \n",
    "    cohort = cohort_dict[(user_id, trade_id)]\n",
    "    \n",
    "    if cohort is None:\n",
    "        return None\n",
    "    \n",
    "    date_ranks = compute_df[(compute_df['open_date2'] == date_observed) & (compute_df['user_id'].isin(cohort))]\n",
    "    min_rank = None\n",
    "    if not date_ranks.empty:\n",
    "        min_rank = date_ranks['zulu_rank'].min()\n",
    "    \n",
    "    return min_rank"
   ],
   "id": "1fc6b6e8c51bf007",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T15:16:53.509819Z",
     "start_time": "2024-12-27T15:16:24.099398Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dicts\n",
    "\n",
    "exchange_rates_dict = {}\n",
    "for _, row in er.iterrows():\n",
    "    currency = row['unit']\n",
    "    date = row['time']\n",
    "    close_price = row['close']\n",
    "    \n",
    "    if currency not in exchange_rates_dict:\n",
    "        exchange_rates_dict[currency] = {}\n",
    "    \n",
    "    exchange_rates_dict[currency][date] = close_price\n",
    "    \n",
    "rank_dict = {}\n",
    "for _, row in compute.iterrows():\n",
    "    user_id = row['user_id']\n",
    "    date = row['open_date2']\n",
    "    zulu_rank = row['zulu_rank']\n",
    "    \n",
    "    if user_id not in rank_dict:\n",
    "        rank_dict[user_id] = {}\n",
    "    rank_dict[user_id][date] = zulu_rank"
   ],
   "id": "3791acca7e08bd65",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T15:16:53.529536Z",
     "start_time": "2024-12-27T15:16:53.510860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def final_derived_dataframe(trading_func, overview_func, er_dict_func, compute_func):\n",
    "    overview_func_scrape_dict = create_user_scrapes_dict(overview_func)\n",
    "    derived_variables = create_derived_variables(trading_func, overview_func_scrape_dict)\n",
    "    \n",
    "    derived_variables['Tij'] = (derived_variables['date_observed'] - derived_variables['date_open']).dt.total_seconds()\n",
    "    \n",
    "    derived_variables[['neg_rate_diff', '24hr_avg_rate', 'fx_rate_idx']] = derived_variables.apply(calculate_rates, axis=1)\n",
    "\n",
    "    derived_variables['gain'] = derived_variables.apply(calculate_gain, axis=1)\n",
    "    \n",
    "    derived_variables[['rank', 'rank_change', 'avg_rank_1m']] = derived_variables.apply(calculate_rank_and_change, axis=1)\n",
    "    \n",
    "    derived_variables[['conc_transactions', 'conc_currencies', 'dispos_effect']] = derived_variables.apply(lambda row: count_concurrent_trades_and_calculate_dispos_effect(row, trading_func, er_dict_func), axis=1)\n",
    "    \n",
    "    new_columns = ['followers', 'amount_following', 'total_follower_profit', 'gain_days', 'avg_slippage']\n",
    "    derived_variables[new_columns] = derived_variables.apply(lambda row: add_compute_columns(row, compute_func), axis=1)\n",
    "    \n",
    "    derived_variables = derived_variables.sort_values(['user_id', 'trade_no', 'observation_number'])\n",
    "    \n",
    "    # Initialize the prev_followers column with None\n",
    "    derived_variables['prev_followers'] = None\n",
    "    \n",
    "    # Initialize variables to keep track of the previous row\n",
    "    prev_user = None\n",
    "    prev_trade = None\n",
    "    prev_followers = None\n",
    "    \n",
    "    # Iterate through the DataFrame\n",
    "    for index, row in derived_variables.iterrows():\n",
    "        current_user = row['user_id']\n",
    "        current_trade = row['trade_no']\n",
    "        current_obs = row['observation_number']\n",
    "        \n",
    "        # If this is a new user or a new trade, reset prev_followers\n",
    "        if current_user != prev_user or current_trade != prev_trade:\n",
    "            prev_followers = None\n",
    "        elif current_obs > 1:  # Not the first observation of the trade\n",
    "            derived_variables.at[index, 'prev_followers'] = prev_followers\n",
    "        \n",
    "        # Update the previous values for the next iteration\n",
    "        prev_user = current_user\n",
    "        prev_trade = current_trade\n",
    "        prev_followers = row['followers']\n",
    "        \n",
    "    directory = 'garsh-files'\n",
    "\n",
    "    garsh_dict = {}\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        currency = filename[6:-4] \n",
    "        \n",
    "        df = pd.read_csv(f\"{directory}/{filename}\")\n",
    "        \n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        df['log-garch'] = df['log-garch'].astype(float).round(3)\n",
    "        \n",
    "        garsh_dict[currency] = dict(zip(df['date'], df['log-garch']))\n",
    "        \n",
    "    for index, row in derived_variables.iterrows():\n",
    "        currency = row['currency'].replace('/', '')\n",
    "        date_obs = row['date_observed'].floor('D')\n",
    "        \n",
    "        if currency in garsh_dict:\n",
    "            if date_obs in garsh_dict[currency]:\n",
    "                derived_variables.at[index, 'log_garch'] = garsh_dict[currency][date_obs]\n",
    "                \n",
    "    derived_variables['date_open'] = pd.to_datetime(derived_variables['date_open'])\n",
    "    derived_variables['date_observed'] = pd.to_datetime(derived_variables['date_observed'])\n",
    "    compute_func['open_date2'] = pd.to_datetime(compute_func['open_date2'])\n",
    "    \n",
    "    # Initialize cohort dictionary\n",
    "    cohort_dict = {}\n",
    "    \n",
    "    # Calculate cohort_min_rank\n",
    "    derived_variables['cohort_min_rank'] = derived_variables.apply(lambda row: calculate_cohort_min_rank(row, cohort_dict, compute_func), axis=1)\n",
    "    \n",
    "    derived_variables = derived_variables.sort_values(['user_id', 'trade_id', 'observation_number'])\n",
    "    \n",
    "    # Initialize views_change column with zeros\n",
    "    derived_variables['views_change'] = 0\n",
    "    \n",
    "    # Initialize variables to keep track of the previous row\n",
    "    prev_user = None\n",
    "    prev_trade = None\n",
    "    first_views = None\n",
    "    \n",
    "    # Iterate through the DataFrame\n",
    "    for index, row in derived_variables.iterrows():\n",
    "        current_user = row['user_id']\n",
    "        current_trade = row['trade_id']\n",
    "        current_views = row['views']\n",
    "        \n",
    "        # If this is a new user or a new trade, reset first_views\n",
    "        if current_user != prev_user or current_trade != prev_trade:\n",
    "            first_views = current_views\n",
    "        \n",
    "        # Calculate views_change\n",
    "        views_change = current_views - first_views\n",
    "        derived_variables.at[index, 'views_change'] = views_change\n",
    "        \n",
    "        # Update the previous values for the next iteration\n",
    "        prev_user = current_user\n",
    "        prev_trade = current_trade\n",
    "        \n",
    "    derived_variables_columns = 'user_id, trade_id, trade_no, observation_number, date_open, date_closed, date_observed, views, views_previous, views_change, currency, lots, cum_day, cum_profit_in_pips, cum_trades, Tij, neg_rate_diff, 24hr_avg_rate, fx_rate_idx, gain, rank, rank_change, avg_rank_1m, cohort_min_rank, conc_transactions, conc_currencies, dispos_effect, followers, prev_followers, amount_following, total_follower_profit, gain_days, avg_slippage, log_garch'\n",
    "    derived_variables_columns = derived_variables_columns.split(', ')\n",
    "    \n",
    "    derived_variables = derived_variables.reindex(columns=derived_variables_columns)\n",
    "    \n",
    "    derived_variables = derived_variables.replace([None, np.nan, '', 'NaN', 'nan'], '.', regex=True)\n",
    "\n",
    "    return derived_variables"
   ],
   "id": "f671b97cb61c1168",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T15:16:56.656248Z",
     "start_time": "2024-12-27T15:16:56.652307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dispos_effect_derived_variables(trading_func, overview_func, er_dict_func):\n",
    "    overview_func_scrape_dict = create_user_scrapes_dict(overview_func)\n",
    "    derived_variables = create_derived_variables(trading_func, overview_func_scrape_dict)\n",
    "    \n",
    "        \n",
    "    derived_variables[['conc_transactions', 'conc_currencies', 'n_open_gain', 'n_open_loss', 'n_closed_gain', 'n_closed_loss', 'prop_closed_gains', 'prop_closed_loss', 'dispos_effect']] = derived_variables.apply(lambda row: count_concurrent_trades_and_calculate_dispos_effect(row, trading_func, er_dict_func), axis=1)\n",
    "    \n",
    "    derived_variables = derived_variables.replace([None, np.nan, '', 'NaN', 'nan'], '.', regex=True)\n",
    "\n",
    "    return derived_variables"
   ],
   "id": "c40355aed9f668af",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T15:17:51.564527Z",
     "start_time": "2024-12-27T15:16:58.434758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unique_users = trading_history['user_id'].unique()\n",
    "\n",
    "# List to store results for each user\n",
    "results = []\n",
    "    \n",
    "for user_id in tqdm(unique_users, desc=\"Processing users\"):\n",
    "    try:\n",
    "        # Create a subset for the current user\n",
    "        mask = (trading_history['user_id'] == user_id)\n",
    "        trading_dummy = trading_history[mask].copy()\n",
    "        trading_dummy.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Apply your function\n",
    "        user_result = dispos_effect_derived_variables(trading_dummy, overview, exchange_rates_dict)\n",
    "        \n",
    "        # Append the result to our list\n",
    "        results.append(user_result)\n",
    "        \n",
    "        print(f\"Processed user {user_id}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing user {user_id}: {e}\")\n",
    "    \n",
    "# Combine all results into a single DataFrame\n",
    "final_result = pd.concat(results, ignore_index=True)\n",
    "final_result = final_result[['user_id', 'trade_id', 'trade_no', 'observation_number', 'date_open', 'date_closed', 'date_observed', 'conc_transactions', 'conc_currencies', 'n_open_gain', 'n_open_loss', 'n_closed_gain', 'n_closed_loss', 'prop_closed_gains', 'prop_closed_loss', 'dispos_effect']]\n",
    "\n",
    "final_csv_file_name = 'disposition_effect_all_parameters.csv'\n",
    "\n",
    "# Save the final result to a CSV file\n",
    "final_result.to_csv(f'{final_csv_file_name}', index=False)\n",
    "\n",
    "print(f\"Processing complete. Results saved to '{final_csv_file_name}'\")"
   ],
   "id": "24e4e2acf3aaffc1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   0%|          | 1/410 [00:02<16:56,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 24632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   0%|          | 2/410 [00:04<14:29,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 388129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   1%|          | 3/410 [00:06<14:30,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 373754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   1%|          | 4/410 [00:09<17:33,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 300553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   1%|          | 5/410 [00:13<20:09,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 371337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   1%|▏         | 6/410 [00:15<17:07,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 387661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   2%|▏         | 7/410 [00:16<15:11,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 388105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   2%|▏         | 8/410 [00:20<18:03,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 373440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   2%|▏         | 9/410 [00:23<18:20,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 326740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   2%|▏         | 10/410 [00:25<17:53,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 364239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   3%|▎         | 11/410 [00:27<15:49,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 385427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   3%|▎         | 12/410 [00:29<14:53,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 378386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   3%|▎         | 13/410 [00:31<14:40,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 388712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   3%|▎         | 14/410 [00:33<14:30,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 372916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   4%|▎         | 15/410 [00:39<21:32,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 371823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   4%|▍         | 16/410 [00:41<18:16,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 378855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   4%|▍         | 17/410 [00:42<16:03,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 378804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   4%|▍         | 18/410 [00:44<14:30,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 388926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   5%|▍         | 19/410 [00:48<17:03,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 41016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   5%|▍         | 20/410 [00:50<15:52,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 339117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   5%|▌         | 21/410 [00:51<14:31,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed user 383057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing users:   5%|▌         | 21/410 [00:52<16:12,  2.50s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 14\u001B[0m\n\u001B[1;32m     11\u001B[0m trading_dummy\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     13\u001B[0m \u001B[38;5;66;03m# Apply your function\u001B[39;00m\n\u001B[0;32m---> 14\u001B[0m user_result \u001B[38;5;241m=\u001B[39m \u001B[43mdispos_effect_derived_variables\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrading_dummy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moverview\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexchange_rates_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Append the result to our list\u001B[39;00m\n\u001B[1;32m     17\u001B[0m results\u001B[38;5;241m.\u001B[39mappend(user_result)\n",
      "Cell \u001B[0;32mIn[7], line 2\u001B[0m, in \u001B[0;36mdispos_effect_derived_variables\u001B[0;34m(trading_func, overview_func, er_dict_func)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdispos_effect_derived_variables\u001B[39m(trading_func, overview_func, er_dict_func):\n\u001B[0;32m----> 2\u001B[0m     overview_func_scrape_dict \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_user_scrapes_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43moverview_func\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     derived_variables \u001B[38;5;241m=\u001B[39m create_derived_variables(trading_func, overview_func_scrape_dict)\n\u001B[1;32m      6\u001B[0m     derived_variables[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconc_transactions\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconc_currencies\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_open_gain\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_open_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_closed_gain\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn_closed_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprop_closed_gains\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprop_closed_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdispos_effect\u001B[39m\u001B[38;5;124m'\u001B[39m]] \u001B[38;5;241m=\u001B[39m derived_variables\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m row: count_concurrent_trades_and_calculate_dispos_effect(row, trading_func, er_dict_func), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[0;32mIn[4], line 5\u001B[0m, in \u001B[0;36mcreate_user_scrapes_dict\u001B[0;34m(overview_df)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate_user_scrapes_dict\u001B[39m(overview_df):\n\u001B[1;32m      4\u001B[0m     user_scrapes \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m----> 5\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _, row \u001B[38;5;129;01min\u001B[39;00m overview_df\u001B[38;5;241m.\u001B[39miterrows():\n\u001B[1;32m      6\u001B[0m         user_id \u001B[38;5;241m=\u001B[39m row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124muserid\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m      7\u001B[0m         scrape_date \u001B[38;5;241m=\u001B[39m row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mscraped_on\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[0;32m~/jabr/jabr_data_analysis/.venv/lib/python3.9/site-packages/pandas/core/frame.py:1554\u001B[0m, in \u001B[0;36mDataFrame.iterrows\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1552\u001B[0m using_cow \u001B[38;5;241m=\u001B[39m using_copy_on_write()\n\u001B[1;32m   1553\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalues):\n\u001B[0;32m-> 1554\u001B[0m     s \u001B[38;5;241m=\u001B[39m \u001B[43mklass\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m   1555\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m using_cow \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mgr\u001B[38;5;241m.\u001B[39mis_single_block:\n\u001B[1;32m   1556\u001B[0m         s\u001B[38;5;241m.\u001B[39m_mgr\u001B[38;5;241m.\u001B[39madd_references(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mgr)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "File \u001B[0;32m~/jabr/jabr_data_analysis/.venv/lib/python3.9/site-packages/pandas/core/series.py:584\u001B[0m, in \u001B[0;36mSeries.__init__\u001B[0;34m(self, data, index, dtype, name, copy, fastpath)\u001B[0m\n\u001B[1;32m    582\u001B[0m         data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m    583\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 584\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43msanitize_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    586\u001B[0m     manager \u001B[38;5;241m=\u001B[39m _get_option(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode.data_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m, silent\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    587\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m manager \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mblock\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/jabr/jabr_data_analysis/.venv/lib/python3.9/site-packages/pandas/core/construction.py:606\u001B[0m, in \u001B[0;36msanitize_array\u001B[0;34m(data, index, dtype, copy, allow_2d)\u001B[0m\n\u001B[1;32m    604\u001B[0m subarr \u001B[38;5;241m=\u001B[39m data\n\u001B[1;32m    605\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m:\n\u001B[0;32m--> 606\u001B[0m     subarr \u001B[38;5;241m=\u001B[39m \u001B[43mmaybe_infer_to_datetimelike\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    607\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    608\u001B[0m         object_index\n\u001B[1;32m    609\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m using_pyarrow_string_dtype()\n\u001B[1;32m    610\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m is_string_dtype(subarr)\n\u001B[1;32m    611\u001B[0m     ):\n\u001B[1;32m    612\u001B[0m         \u001B[38;5;66;03m# Avoid inference when string option is set\u001B[39;00m\n\u001B[1;32m    613\u001B[0m         subarr \u001B[38;5;241m=\u001B[39m data\n",
      "File \u001B[0;32m~/jabr/jabr_data_analysis/.venv/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1190\u001B[0m, in \u001B[0;36mmaybe_infer_to_datetimelike\u001B[0;34m(value)\u001B[0m\n\u001B[1;32m   1185\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m value\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# error: Incompatible return value type (got \"Union[ExtensionArray,\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;66;03m# ndarray[Any, Any]]\", expected \"Union[ndarray[Any, Any], DatetimeArray,\u001B[39;00m\n\u001B[1;32m   1189\u001B[0m \u001B[38;5;66;03m# TimedeltaArray, PeriodArray, IntervalArray]\")\u001B[39;00m\n\u001B[0;32m-> 1190\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmaybe_convert_objects\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[return-value]\u001B[39;49;00m\n\u001B[1;32m   1191\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1192\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# Here we do not convert numeric dtypes, as if we wanted that,\u001B[39;49;00m\n\u001B[1;32m   1193\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m#  numpy would have done it for us.\u001B[39;49;00m\n\u001B[1;32m   1194\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconvert_numeric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconvert_non_numeric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1196\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype_if_all_nat\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mM8[ns]\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1197\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32mlib.pyx:2543\u001B[0m, in \u001B[0;36mpandas._libs.lib.maybe_convert_objects\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/jabr/jabr_data_analysis/.venv/lib/python3.9/site-packages/numpy/core/numeric.py:274\u001B[0m, in \u001B[0;36mfull\u001B[0;34m(shape, fill_value, dtype, order, like)\u001B[0m\n\u001B[1;32m    270\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_full_dispatcher\u001B[39m(shape, fill_value, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, order\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m, like\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    271\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m(like,)\n\u001B[0;32m--> 274\u001B[0m \u001B[38;5;129m@set_array_function_like_doc\u001B[39m\n\u001B[1;32m    275\u001B[0m \u001B[38;5;129m@set_module\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumpy\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    276\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfull\u001B[39m(shape, fill_value, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, order\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m*\u001B[39m, like\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    277\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;124;03m    Return a new array of given shape and type, filled with `fill_value`.\u001B[39;00m\n\u001B[1;32m    279\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    320\u001B[0m \n\u001B[1;32m    321\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m like \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-28T04:41:24.010080Z",
     "start_time": "2024-06-28T04:41:23.996154Z"
    }
   },
   "cell_type": "code",
   "source": "final_result",
   "id": "9aeae29cac753395",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        user_id   trade_id  trade_no  observation_number           date_open  \\\n",
       "0         24632  514812394         1                   1 2019-10-14 20:11:11   \n",
       "1         24632  514812394         1                   2 2019-10-14 20:11:11   \n",
       "2         24632  514812394         1                   3 2019-10-14 20:11:11   \n",
       "3         24632  514812394         1                   4 2019-10-14 20:11:11   \n",
       "4         24632  514812394         1                   5 2019-10-14 20:11:11   \n",
       "...         ...        ...       ...                 ...                 ...   \n",
       "102427   378883  506804088         1                   2 2019-07-16 04:56:55   \n",
       "102428   378883  506843815         2                   1 2019-07-16 09:26:09   \n",
       "102429   378883  506843815         2                   2 2019-07-16 09:26:09   \n",
       "102430   378883  506733468         3                   1 2019-07-15 12:07:44   \n",
       "102431   378883  506733468         3                   2 2019-07-15 12:07:44   \n",
       "\n",
       "               date_closed       date_observed  conc_transactions  \\\n",
       "0      2019-11-17 17:23:15 2019-10-21 22:31:00                3.0   \n",
       "1      2019-11-17 17:23:15 2019-10-22 22:25:00                3.0   \n",
       "2      2019-11-17 17:23:15 2019-10-23 22:25:00                3.0   \n",
       "3      2019-11-17 17:23:15 2019-10-27 22:25:00                3.0   \n",
       "4      2019-11-17 17:23:15 2019-10-28 22:25:00                3.0   \n",
       "...                    ...                 ...                ...   \n",
       "102427 2019-07-24 06:50:33 2019-07-24 06:50:33                3.0   \n",
       "102428 2019-07-24 06:50:33 2019-07-24 01:29:00                3.0   \n",
       "102429 2019-07-24 06:50:33 2019-07-24 06:50:33                3.0   \n",
       "102430 2019-07-24 06:50:33 2019-07-24 01:29:00                3.0   \n",
       "102431 2019-07-24 06:50:33 2019-07-24 06:50:33                3.0   \n",
       "\n",
       "        conc_currencies  n_open_gain  n_open_loss  n_closed_gain  \\\n",
       "0                   3.0          2.0          0.0            0.0   \n",
       "1                   3.0          2.0          0.0            0.0   \n",
       "2                   3.0          2.0          0.0            0.0   \n",
       "3                   3.0          2.0          0.0            0.0   \n",
       "4                   3.0          2.0          0.0            0.0   \n",
       "...                 ...          ...          ...            ...   \n",
       "102427              1.0          0.0          0.0            3.0   \n",
       "102428              1.0          0.0          0.0            2.0   \n",
       "102429              1.0          0.0          0.0            3.0   \n",
       "102430              1.0          0.0          0.0            2.0   \n",
       "102431              1.0          0.0          0.0            3.0   \n",
       "\n",
       "        n_closed_loss  prop_closed_gains  prop_closed_loss  dispos_effect  \n",
       "0                 0.0                0.0               0.0            0.0  \n",
       "1                 0.0                0.0               0.0            0.0  \n",
       "2                 0.0                0.0               0.0            0.0  \n",
       "3                 0.0                0.0               0.0            0.0  \n",
       "4                 0.0                0.0               0.0            0.0  \n",
       "...               ...                ...               ...            ...  \n",
       "102427            0.0                1.0               0.0            1.0  \n",
       "102428            1.0                1.0               1.0            0.0  \n",
       "102429            0.0                1.0               0.0            1.0  \n",
       "102430            1.0                1.0               1.0            0.0  \n",
       "102431            0.0                1.0               0.0            1.0  \n",
       "\n",
       "[102432 rows x 16 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>trade_id</th>\n",
       "      <th>trade_no</th>\n",
       "      <th>observation_number</th>\n",
       "      <th>date_open</th>\n",
       "      <th>date_closed</th>\n",
       "      <th>date_observed</th>\n",
       "      <th>conc_transactions</th>\n",
       "      <th>conc_currencies</th>\n",
       "      <th>n_open_gain</th>\n",
       "      <th>n_open_loss</th>\n",
       "      <th>n_closed_gain</th>\n",
       "      <th>n_closed_loss</th>\n",
       "      <th>prop_closed_gains</th>\n",
       "      <th>prop_closed_loss</th>\n",
       "      <th>dispos_effect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24632</td>\n",
       "      <td>514812394</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-10-14 20:11:11</td>\n",
       "      <td>2019-11-17 17:23:15</td>\n",
       "      <td>2019-10-21 22:31:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24632</td>\n",
       "      <td>514812394</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-10-14 20:11:11</td>\n",
       "      <td>2019-11-17 17:23:15</td>\n",
       "      <td>2019-10-22 22:25:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24632</td>\n",
       "      <td>514812394</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2019-10-14 20:11:11</td>\n",
       "      <td>2019-11-17 17:23:15</td>\n",
       "      <td>2019-10-23 22:25:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24632</td>\n",
       "      <td>514812394</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-10-14 20:11:11</td>\n",
       "      <td>2019-11-17 17:23:15</td>\n",
       "      <td>2019-10-27 22:25:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24632</td>\n",
       "      <td>514812394</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-10-14 20:11:11</td>\n",
       "      <td>2019-11-17 17:23:15</td>\n",
       "      <td>2019-10-28 22:25:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102427</th>\n",
       "      <td>378883</td>\n",
       "      <td>506804088</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-07-16 04:56:55</td>\n",
       "      <td>2019-07-24 06:50:33</td>\n",
       "      <td>2019-07-24 06:50:33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102428</th>\n",
       "      <td>378883</td>\n",
       "      <td>506843815</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-07-16 09:26:09</td>\n",
       "      <td>2019-07-24 06:50:33</td>\n",
       "      <td>2019-07-24 01:29:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102429</th>\n",
       "      <td>378883</td>\n",
       "      <td>506843815</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-07-16 09:26:09</td>\n",
       "      <td>2019-07-24 06:50:33</td>\n",
       "      <td>2019-07-24 06:50:33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102430</th>\n",
       "      <td>378883</td>\n",
       "      <td>506733468</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-07-15 12:07:44</td>\n",
       "      <td>2019-07-24 06:50:33</td>\n",
       "      <td>2019-07-24 01:29:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102431</th>\n",
       "      <td>378883</td>\n",
       "      <td>506733468</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-07-15 12:07:44</td>\n",
       "      <td>2019-07-24 06:50:33</td>\n",
       "      <td>2019-07-24 06:50:33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102432 rows × 16 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T19:49:03.796452Z",
     "start_time": "2024-06-23T19:49:03.791895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = final_result.loc[final_result['user_id'] == 381158]\n",
    "print(result)"
   ],
   "id": "fd520a49a8b0c219",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [user_id, trade_id, trade_no, observation_number, date_open, date_closed, date_observed, views, views_previous, views_change, currency, lots, cum_day, cum_profit_in_pips, cum_trades, Tij, neg_rate_diff, 24hr_avg_rate, fx_rate_idx, gain, rank, rank_change, avg_rank_1m, cohort_min_rank, conc_transactions, conc_currencies, dispos_effect, followers, prev_followers, amount_following, total_follower_profit, gain_days, avg_slippage, log_garch]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 34 columns]\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ea9835991a2b6ec5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
